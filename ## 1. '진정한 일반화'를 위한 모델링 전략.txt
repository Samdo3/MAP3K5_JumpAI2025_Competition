## 1. '진정한 일반화'를 위한 모델링 전략
'진정한 일반화'는 모델이 훈련 데이터의 통계적 분포만 암기하는 것을 넘어, 분자 구조와 활성 사이의 근본적인 규칙을 학습하여 처음 보는 분자에 대해서도 정확한 예측을 하는 것을 의미합니다. 이를 위한 전략은 다음과 같습니다.

#### 1.1. 훈련 목표 재설계: '중요도' 학습시키기
가장 핵심적인 부분입니다. 모델이 '초우량' 분자를 무시하지 않도록 훈련 목표 자체를 바꿔야 합니다.

가중치 부여 (Sample Weighting): pIC50 값에 따라 그룹을 나누고, 그룹별로 다른 가중치를 부여합니다.

초고활성 그룹 (pIC50 > 10): 가중치 x 50 (이 그룹을 틀리면 50배의 페널티)

고활성 그룹 (8 < pIC50 ≤ 10): 가중치 x 5 (이 그룹도 중요하니 5배의 페널티)

일반 그룹 (pIC50 ≤ 8): 가중치 x 1 (기본 페널티)

결과: 모델은 더 이상 전체 평균 오차만 줄이려 하지 않고, 가중치가 높은 '초우량' 분자들의 패턴을 학습하는 데 훨씬 더 많은 노력을 기울이게 됩니다.

#### 1.2. 견고한 검증 전략 수립
모델이 정말 일반화되었는지 올바르게 측정해야 합니다.

계층적 교차 검증 (Stratified K-Fold): 데이터를 나눌 때, 위에서 나눈 pIC50 그룹(초고활성/고활성/일반)의 비율을 각 Fold마다 동일하게 유지해야 합니다. 이렇게 해야 모든 검증 단계에서 모델이 '초우량' 분자를 예측하는 능력을 공정하게 테스트할 수 있습니다.

사용자 정의 평가지표: 전체적인 대회 점수(RMSE 기반)만 보지 말고, 우리가 정말 중요하게 생각하는 부분을 따로 평가해야 합니다. 예를 들어, **"실제 pIC50가 9 이상인 분자들만을 대상으로 한 RMSE 점수"**를 추가 지표로 삼아 모델 성능을 모니터링합니다.

## 2. 도메인 관점에서의 예측 목표
신약 개발의 도메인 지식을 고려할 때, 모델은 단순히 모든 값을 잘 맞추는 것이 아니라 '의사결정'에 도움이 되는 예측을 해야 합니다.

#### 2.1. 최우선 목표: 고활성 분자(High pIC50)를 놓치지 않기
"이 약은 효과가 있는가?": 신약 개발의 첫 질문입니다. 따라서 모델은 특정 pIC50 값 이상(예: 8 또는 9 이상)의 잠재적 '히트' 화합물을 정확하게 예측하는 것이 가장 중요합니다. '다이아몬드'를 '돌멩이'로 예측하는 것(False Negative)이 가장 치명적인 실수입니다.

#### 2.2. 두 번째 목표: 저활성 분자(Low pIC50)를 확실히 가려내기
"이 약은 확실히 효과가 없는가?": 이것 역시 중요한 질문입니다. 효과 없는 화합물에 시간과 비용을 낭비하지 않도록 막아주기 때문입니다.

모델이 분명히 효과 없는 분자(pIC50 < 5 등)를 효과가 좋은 것처럼 예측(False Positive)하는 것도 막아야 합니다.

#### 2.3. 결론: '양 극단'을 잘 맞추는 전문가
결론적으로, 우리가 만들어야 할 모델은 **'양 극단을 잘 맞추는 전문가'**입니다.

pIC50이 높은 영역: 예측의 정밀도(Precision)와 재현율(Recall)이 모두 높아야 합니다. 즉, '히트'라고 예측한 것은 진짜 '히트'여야 하고, 실제 '히트'를 놓쳐서도 안 됩니다.

pIC50이 낮은 영역: 예측의 **정확도(Accuracy)**가 높아야 합니다. 효과 없는 분자는 확실히 효과 없다고 말할 수 있어야 합니다.

중간 영역 (pIC50 6~7.5): 이 영역의 분자들은 어차피 신약 후보로 발전할 가능성이 낮습니다. 따라서 이 구간에서의 예측 오차는 다른 두 극단에서의 오차보다 상대적으로 덜 중요합니다.


### 데이터 수가 부족한 고활성, 초고활성 분자들을 위한 방법
따라서 Mixup과 같은 데이터 증강 기법보다는, 이전에 우리가 논의했던 훈련 방식 자체를 바꾸는 전략이 훨씬 효과적이고 올바른 접근법입니다.

샘플 가중치 (Sample Weighting): 가장 강력하고 직접적인 해결책입니다. pIC50이 높은 '초우량' 분자 27개에 높은 가중치를 부여하여, 모델이 이 샘플들의 학습에 집중하도록 만드는 것입니다.

맞춤형 손실 함수 (Custom Loss Function): pIC50이 높은 영역에서 예측이 틀렸을 때 훨씬 더 큰 페널티를 부과하는 손실 함수를 사용하여, 모델이 해당 영역의 예측 정확도를 높이도록 유도합니다.

특화된 샘플링 (Specialized Sampling): 훈련 시 미니배치(mini-batch)를 구성할 때, '초우량' 분자들이 더 자주 포함되도록 의도적으로 샘플링하는 방식입니다. (일종의 오버샘플링)